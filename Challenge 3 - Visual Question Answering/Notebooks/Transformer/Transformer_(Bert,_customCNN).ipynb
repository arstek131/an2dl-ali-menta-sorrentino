{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer (Bert, customCNN).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUFB-7cAdmr"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import cv2\r\n",
        "import PIL\r\n",
        "from datetime import datetime\r\n",
        "from PIL import Image\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from math import ceil, floor\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_-lEN5HAjqw"
      },
      "source": [
        "#### Constants ####\r\n",
        "TRAIN = True\r\n",
        "SEED = 1234\r\n",
        "img_h = 200\r\n",
        "img_w = 350\r\n",
        "n_channels = 3\r\n",
        "bs = 256;\r\n",
        "dataset_split = 0.8\r\n",
        "num_questions = 0\r\n",
        "\r\n",
        "tf.random.set_seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "\r\n",
        "# Get current working directory\r\n",
        "cwd = os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmND7AaAtyO"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEA3eNYpA1dJ"
      },
      "source": [
        "!unzip drive/MyDrive/Assignment_3/anndl-2020-vqa.zip -d ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cet_DM0KBEnn"
      },
      "source": [
        "imgs_path = os.path.join('/content/VQA_Dataset', 'Images')\r\n",
        "train_json_path = os.path.join('/content/VQA_Dataset', 'train_questions_annotations.json')\r\n",
        "test_json_path = os.path.join('/content/VQA_Dataset', 'test_questions.json')\r\n",
        "\r\n",
        "\r\n",
        "# direct dictionary, word => code\r\n",
        "dictionary = {\r\n",
        "        '0': 0,\r\n",
        "        '1': 1,\r\n",
        "        '2': 2,\r\n",
        "        '3': 3,\r\n",
        "        '4': 4,\r\n",
        "        '5': 5,\r\n",
        "        'apple': 6,\r\n",
        "        'baseball': 7,\r\n",
        "        'bench': 8,\r\n",
        "        'bike': 9,\r\n",
        "        'bird': 10,\r\n",
        "        'black': 11,\r\n",
        "        'blanket': 12,\r\n",
        "        'blue': 13,\r\n",
        "        'bone': 14,\r\n",
        "        'book': 15,\r\n",
        "        'boy': 16,\r\n",
        "        'brown': 17,\r\n",
        "        'cat': 18,\r\n",
        "        'chair': 19,\r\n",
        "        'couch': 20,\r\n",
        "        'dog': 21,\r\n",
        "        'floor': 22,\r\n",
        "        'food': 23,\r\n",
        "        'football': 24,\r\n",
        "        'girl': 25,\r\n",
        "        'grass': 26,\r\n",
        "        'gray': 27,\r\n",
        "        'green': 28,\r\n",
        "        'left': 29,\r\n",
        "        'log': 30,\r\n",
        "        'man': 31,\r\n",
        "        'monkey bars': 32,\r\n",
        "        'no': 33,\r\n",
        "        'nothing': 34,\r\n",
        "        'orange': 35,\r\n",
        "        'pie': 36,\r\n",
        "        'plant': 37,\r\n",
        "        'playing': 38,\r\n",
        "        'red': 39,\r\n",
        "        'right': 40,\r\n",
        "        'rug': 41,\r\n",
        "        'sandbox': 42,\r\n",
        "        'sitting': 43,\r\n",
        "        'sleeping': 44,\r\n",
        "        'soccer': 45,\r\n",
        "        'squirrel': 46,\r\n",
        "        'standing': 47,\r\n",
        "        'stool': 48,\r\n",
        "        'sunny': 49,\r\n",
        "        'table': 50,\r\n",
        "        'tree': 51,\r\n",
        "        'watermelon': 52,\r\n",
        "        'white': 53,\r\n",
        "        'wine': 54,\r\n",
        "        'woman': 55,\r\n",
        "        'yellow': 56,\r\n",
        "        'yes': 57\r\n",
        "}\r\n",
        "\r\n",
        "# inverse dictionary, code => word\r\n",
        "inverse_dictionary = {value:key for key, value in dictionary.items()}\r\n",
        "\r\n",
        "N_CLASSES = len(dictionary)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKjxWnWcC8GE"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\r\n",
        "  ''' constructor '''\r\n",
        "  def __init__(self, answers, imageIDs, input_questions, batch_size, training, max_length,\r\n",
        "               shuffle=True, img_h=128, img_w=128, channels=3, img_generator=None):\r\n",
        "    self.answers = answers\r\n",
        "    self.imageIDs = imageIDs\r\n",
        "    self.input_questions = input_questions\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.shuffle = shuffle\r\n",
        "    self.indexes = np.arange(len(self.answers)) # list of indexes on complete dataset\r\n",
        "    self.max_length = max_length\r\n",
        "    self.training = training\r\n",
        "    self.img_h = img_h\r\n",
        "    self.img_w = img_w\r\n",
        "    self.channels = channels # RGB image\r\n",
        "    self.img_generator = img_generator\r\n",
        "    self.on_epoch_end()\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return int(np.floor(len(self.imageIDs) / self.batch_size))\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    bs_index_start = index * self.batch_size; # if bs = 32, second batch starts from 31 (0 indexed)\r\n",
        "    bs_index_end = bs_index_start + self.batch_size - 1; # if bs = 32, second batch finished at 63 (0 indexed)\r\n",
        "    indexes = self.indexes[bs_index_start:(bs_index_end+1)]\r\n",
        "    \r\n",
        "    # generates array [[RGBimage0m answer0], [RGBimage1, answer1], ...]\r\n",
        "    input_x =  self._generate_x(indexes)\r\n",
        "    \r\n",
        "    if self.training: # if training, return input and also ground truth\r\n",
        "      output_y = self._generate_y(indexes)\r\n",
        "      return (input_x, output_y)\r\n",
        "    \r\n",
        "    else: # if testing, return input only\r\n",
        "      return input_x\r\n",
        "\r\n",
        "  def on_epoch_end(self):\r\n",
        "    if self.shuffle:\r\n",
        "      np.random.shuffle(self.indexes)\r\n",
        "\r\n",
        "  def _generate_x(self, indexes):\r\n",
        "    # init result containers\r\n",
        "    RGBimages = np.empty((self.batch_size, self.img_h, self.img_w, self.channels))\r\n",
        "    input_ids = np.empty((self.batch_size, self.max_length))\r\n",
        "    attention_mask = np.empty((self.batch_size, self.max_length))\r\n",
        "\r\n",
        "    for i, ID in enumerate(indexes):\r\n",
        "      RGBimages[i, ] = self._load_image(self.imageIDs[ID], self.img_w, self.img_h)\r\n",
        "      input_ids[i,] = self.input_questions[ID]['input_ids']\r\n",
        "      #questions[i,1,] = self.input_questions[ID]['token_type_ids']\r\n",
        "      attention_mask[i,] = self.input_questions[ID]['attention_mask']\r\n",
        "\r\n",
        "    return {'image' : RGBimages, 'input_ids' : input_ids, 'attention_mask' : attention_mask}\r\n",
        "\r\n",
        "  def _generate_y(self, indexes):\r\n",
        "    y = np.empty((self.batch_size, N_CLASSES), dtype=int)\r\n",
        "    \r\n",
        "    # transforming answer to categorical\r\n",
        "    indexed_answers = [self.answers[i] for i in indexes]\r\n",
        "    \r\n",
        "    categorical = tf.keras.utils.to_categorical(indexed_answers, num_classes=N_CLASSES)\r\n",
        "\r\n",
        "    # enum => [[0, 64], [1, 42], [2, 76], ...]\r\n",
        "    for i, elem in enumerate(categorical):\r\n",
        "      y[i] = elem;\r\n",
        "\r\n",
        "    return y\r\n",
        "\r\n",
        "  def _load_image(self, img_name, img_w, img_h):\r\n",
        "    rgba_image = PIL.Image.open(imgs_path + '/' + img_name + \".png\")\r\n",
        "    rgb_image = rgba_image.convert('RGB')\r\n",
        "    image = cv2.resize(np.array(rgb_image), (img_w, img_h))\r\n",
        "    if self.img_generator is not None:\r\n",
        "      img_t = self.img_generator.get_random_transform(image.shape, seed=SEED)\r\n",
        "      image = self.img_generator.apply_transform(image, img_t)   \r\n",
        "    image = image/ 255.\r\n",
        "    return image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTlCUJFYDtUv"
      },
      "source": [
        "# extracts (questions, imageIDs, answers) from training json\r\n",
        "def parseTrainJson(data, first, last):\r\n",
        "  imageIDs = []\r\n",
        "  questions = []\r\n",
        "  answers = []\r\n",
        "\r\n",
        "  for key in list(data)[first:last]:\r\n",
        "    question = data[key]['question'].lower().split(\" \") # splitting questio into words\r\n",
        "    question[-1] = question[-1].replace(\"?\", \"\") # removing question mark\r\n",
        "    \r\n",
        "    imageID = data[key]['image_id']\r\n",
        "    answer = data[key]['answer']\r\n",
        "\r\n",
        "    questions.append(question)\r\n",
        "    imageIDs.append(imageID)\r\n",
        "    answers.append(dictionary[answer]) # appending equivalent number of word\r\n",
        "     \r\n",
        "  return questions, imageIDs, answers\r\n",
        "\r\n",
        "# extracts (questionIDs, questions, imageIDs) from test json\r\n",
        "def parseTestJson(data):\r\n",
        "  questionIDs = []\r\n",
        "  imageIDs = []\r\n",
        "  questions = []\r\n",
        "\r\n",
        "  for key in data:\r\n",
        "    questionIDs.append(key)\r\n",
        "    imageID = data[key]['image_id']\r\n",
        "    question = data[key]['question'].split(\" \") # splitting questio into words\r\n",
        "    question[-1] = question[-1].replace(\"?\", \"\") # removing question mark\r\n",
        "\r\n",
        "    imageIDs.append(imageID)\r\n",
        "    questions.append(question)\r\n",
        "\r\n",
        "  return questionIDs, questions, imageIDs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnD3U8hUD2-i"
      },
      "source": [
        "# train and validation splitting intervals\r\n",
        "\r\n",
        "# train/valid\r\n",
        "with open(train_json_path, 'r') as f:\r\n",
        "  data = json.load(f)\r\n",
        "  num_questions = len(data)\r\n",
        "  num_train_questions = floor(num_questions * dataset_split)\r\n",
        "  num_valid_questions = num_questions - num_train_questions\r\n",
        "  (train_questions, train_imageIDs, train_answers) = parseTrainJson(data, 0, num_train_questions);  # train\r\n",
        "  (valid_questions, valid_imageIDs, valid_answers) = parseTrainJson(data, num_train_questions, num_questions);  # valid\r\n",
        "\r\n",
        "# test\r\n",
        "with open(test_json_path, 'r') as f:\r\n",
        "  test_data = json.load(f)\r\n",
        "  (test_questionIDs, test_questions, test_imageIDs) = parseTestJson(test_data) # test"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgt1wLwDBQ-D"
      },
      "source": [
        "!pip install -q transformers tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I2a62ETBuP4"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\r\n",
        "vocabulary = tokenizer.get_vocab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfITZEHZFBf5"
      },
      "source": [
        "max_length = 23 #calculated max\r\n",
        "bert_input_train = []\r\n",
        "for line in tqdm(train_questions):\r\n",
        "  bert_input_train.append(tokenizer.encode_plus(\r\n",
        "                                              line,\r\n",
        "                                              add_special_tokens=True,\r\n",
        "                                              truncation=True,\r\n",
        "                                              max_length=max_length,\r\n",
        "                                              padding='max_length',\r\n",
        "                                              return_attention_mask=True,\r\n",
        "                                              is_split_into_words=True))\r\n",
        "bert_input_valid = []\r\n",
        "for line in tqdm(valid_questions):\r\n",
        "  bert_input_valid.append(tokenizer.encode_plus(\r\n",
        "                                              line,\r\n",
        "                                              add_special_tokens=True,\r\n",
        "                                              truncation=True,\r\n",
        "                                              max_length=max_length,\r\n",
        "                                              padding='max_length',\r\n",
        "                                              return_attention_mask=True,\r\n",
        "                                              is_split_into_words=True))\r\n",
        "bert_input_test = []\r\n",
        "for line in tqdm(test_questions):\r\n",
        "  bert_input_test.append(tokenizer.encode_plus(\r\n",
        "                                              line,\r\n",
        "                                              add_special_tokens=True,\r\n",
        "                                              truncation=True,\r\n",
        "                                              max_length=max_length,\r\n",
        "                                              padding = 'max_length',\r\n",
        "                                              return_attention_mask=True,\r\n",
        "                                              is_split_into_words=True))\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnxcZVRZp8fK"
      },
      "source": [
        "print(train_questions[12])\n",
        "print(tokenizer.encode(train_questions[12]))\n",
        "print(tokenizer.decode(bert_input_train[12]['input_ids']))\n",
        "print(bert_input_train[12]['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss4ypgXHDz3L"
      },
      "source": [
        "train_generator = DataGenerator(answers=train_answers, \r\n",
        "                                imageIDs=train_imageIDs, \r\n",
        "                                input_questions=bert_input_train,\r\n",
        "                                batch_size=bs,\r\n",
        "                                shuffle=True,\r\n",
        "                                training=True,\r\n",
        "                                img_h=img_h,\r\n",
        "                                img_w=img_w,\r\n",
        "                                channels=n_channels,\r\n",
        "                                max_length=max_length)\r\n",
        "\r\n",
        "valid_generator = DataGenerator(answers=valid_answers, \r\n",
        "                                imageIDs=valid_imageIDs, \r\n",
        "                                input_questions=bert_input_valid,\r\n",
        "                                batch_size=bs,\r\n",
        "                                shuffle=False,\r\n",
        "                                training=True,\r\n",
        "                                img_h=img_h,\r\n",
        "                                img_w=img_w,\r\n",
        "                                channels=n_channels,\r\n",
        "                                max_length=max_length)\r\n",
        "\r\n",
        "test_generator = DataGenerator(answers=test_questionIDs, \r\n",
        "                                imageIDs=test_imageIDs, \r\n",
        "                                input_questions=bert_input_test,\r\n",
        "                                batch_size=1,\r\n",
        "                                shuffle=False,\r\n",
        "                                training=False,\r\n",
        "                                img_h=img_h,\r\n",
        "                                img_w=img_w,\r\n",
        "                                channels=n_channels,\r\n",
        "                                max_length=max_length)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki7uuPjtN8Hi"
      },
      "source": [
        "from transformers import TFAutoModel\r\n",
        "from transformers import BertModel, BertConfig\r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "config = BertConfig(use_cache=True, output_attentions=False, is_decoder=True)\r\n",
        "\r\n",
        "def VQA(out_dim = 768):\r\n",
        "  drop_rate_conv = 0.2\r\n",
        "  drop_rate_ffnn = 0.5\r\n",
        "  \r\n",
        "  ## InputsÂ ##\r\n",
        "  input_image = tf.keras.Input(shape=(img_h, img_w, n_channels), name='image')\r\n",
        "  input_ids = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\r\n",
        "  attention_mask = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\r\n",
        "\r\n",
        "  ## CNN image processing##\r\n",
        "  # Conv block 1\r\n",
        "  conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform')(input_image)\r\n",
        "  batch1 = tf.keras.layers.BatchNormalization()(conv1)\r\n",
        "  act1 = tf.keras.layers.Activation('relu')(batch1)\r\n",
        "  pool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(act1)\r\n",
        "  drop1 = tf.keras.layers.Dropout(drop_rate_conv, seed=SEED)(pool1)\r\n",
        "\r\n",
        "  # Conv block 2\r\n",
        "  conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform')(drop1)\r\n",
        "  batch2 = tf.keras.layers.BatchNormalization()(conv2)\r\n",
        "  act2 = tf.keras.layers.Activation('relu')(batch2)\r\n",
        "  pool2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(act2)\r\n",
        "  drop2 = tf.keras.layers.Dropout(drop_rate_conv, seed=SEED)(pool2)\r\n",
        "\r\n",
        "  # Conv block 3\r\n",
        "  conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_initializer='he_uniform')(drop2)\r\n",
        "  batch3 = tf.keras.layers.BatchNormalization()(conv3)\r\n",
        "  act3 = tf.keras.layers.Activation('relu')(batch3)\r\n",
        "  pool3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(act3)\r\n",
        "  drop3 = tf.keras.layers.Dropout(drop_rate_conv, seed=SEED)(pool3)\r\n",
        "\r\n",
        "  # Conv block 4\r\n",
        "  gap1 = tf.keras.layers.GlobalAveragePooling2D()(drop3)\r\n",
        "  dense1 = tf.keras.layers.Dense(units=out_dim, kernel_initializer='he_uniform')(gap1)\r\n",
        "  batch4 = keras.layers.BatchNormalization()(dense1)\r\n",
        "  act4 = tf.keras.layers.Activation('relu')(batch4)\r\n",
        "  drop4 = tf.keras.layers.Dropout(drop_rate_conv, seed=SEED)(act4)\r\n",
        "\r\n",
        "  ## BERT transformer ##\r\n",
        "  bert = TFAutoModel.from_pretrained('bert-base-uncased', config=config)\r\n",
        "  embeddings = bert(\r\n",
        "        input_ids=input_ids, attention_mask=attention_mask\r\n",
        "  )[0]\r\n",
        "\r\n",
        "  #embeddings = bert(\r\n",
        "  #      input_ids=input_ids, attention_mask=attention_mask\r\n",
        "  #)[1] This is te unpooled output. requires max-pooling since output is (None, 23, 768)\r\n",
        "  gap2 = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\r\n",
        "  denseX = tf.keras.layers.Dense(units=out_dim, kernel_initializer='he_uniform')(gap2)\r\n",
        "  #denseX = tf.keras.layers.Dense(units=out_dim, kernel_initializer='he_uniform')(embeddings)\r\n",
        "  batchX = tf.keras.layers.BatchNormalization()(denseX)\r\n",
        "  actX = tf.keras.layers.Activation('relu')(batchX)\r\n",
        "  dropX = tf.keras.layers.Dropout(drop_rate_ffnn, seed=SEED)(actX)\r\n",
        "  \r\n",
        "  ## Merge ##\r\n",
        "  merge = tf.keras.layers.Multiply()([drop4, dropX])\r\n",
        "  dense = tf.keras.layers.Dense(units=out_dim, kernel_initializer='he_uniform')(merge)\r\n",
        "  batch = tf.keras.layers.BatchNormalization()(dense)\r\n",
        "  act = tf.keras.layers.Activation('relu')(batch)\r\n",
        "  drop = tf.keras.layers.Dropout(drop_rate_ffnn, seed=SEED)(act)\r\n",
        "  out = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(drop)\r\n",
        "  VQA_model = tf.keras.models.Model(inputs=[input_image, input_ids, attention_mask], outputs=out)\r\n",
        "\r\n",
        "  return VQA_model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iGwO1zVQ7U4"
      },
      "source": [
        "VQA_net = VQA(out_dim=768)\r\n",
        "print(VQA_net.layers[18])\r\n",
        "VQA_net.layers[18].trainable = False # freezing transformer\r\n",
        "VQA_net.summary()\r\n",
        "tf.keras.utils.plot_model(VQA_net, expand_nested=True, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkTOTezBywb"
      },
      "source": [
        "# loss\r\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "# optimizer\r\n",
        "lr = 1e-3\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "# metrics\r\n",
        "metrics = ['accuracy']\r\n",
        "\r\n",
        "VQA_net.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdIBTAW8DNe5"
      },
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "if TRAIN:  \r\n",
        "  exps_dir = os.path.join(cwd, 'drive/My Drive/Assignment_3/Log/')\r\n",
        "  if not os.path.exists(exps_dir):\r\n",
        "      os.makedirs(exps_dir)\r\n",
        "\r\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\r\n",
        "\r\n",
        "  model_name = 'Baseline'\r\n",
        "\r\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\r\n",
        "  if not os.path.exists(exp_dir):\r\n",
        "      os.makedirs(exp_dir)\r\n",
        "      \r\n",
        "  callbacks = []\r\n",
        "\r\n",
        "  # Model checkpoint\r\n",
        "  # ----------------\r\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\r\n",
        "  if not os.path.exists(ckpt_dir):\r\n",
        "      os.makedirs(ckpt_dir)\r\n",
        "\r\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \r\n",
        "                                                    save_weights_only=True, save_best_only=True)  # False to save the model directly\r\n",
        "  callbacks.append(ckpt_callback)\r\n",
        "\r\n",
        "  # Visualize Learning on Tensorboard\r\n",
        "  # ---------------------------------\r\n",
        "  tb_dir = os.path.join(exp_dir, 'tb_logs')\r\n",
        "  if not os.path.exists(tb_dir):\r\n",
        "      os.makedirs(tb_dir)\r\n",
        "      \r\n",
        "  # By default shows losses and metrics for both training and validation\r\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\r\n",
        "                                              profile_batch=0,\r\n",
        "                                              histogram_freq=0)  # if 1 shows weights histograms\r\n",
        "  callbacks.append(tb_callback)\r\n",
        "\r\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7, verbose=1, cooldown=0)\r\n",
        "  callbacks.append(reduce_lr)\r\n",
        "\r\n",
        "  # Early Stopping\r\n",
        "  # --------------\r\n",
        "  early_stop = True\r\n",
        "  if early_stop:\r\n",
        "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\r\n",
        "      callbacks.append(es_callback)\r\n",
        "  \r\n",
        "\r\n",
        "  VQA_net.fit(x=train_generator,\r\n",
        "            epochs=50,  #### set repeat in training dataset\r\n",
        "            steps_per_epoch=len(train_generator),\r\n",
        "            validation_data=valid_generator,\r\n",
        "            validation_steps=len(valid_generator),\r\n",
        "            callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POQ-L7_13U-z"
      },
      "source": [
        "#VQA_net.save('/content/drive/My Drive/Assignment_3/Saved Models/BertTransformerCustom')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKEHazjDkglQ"
      },
      "source": [
        "def create_csv(results, results_dir='./'):\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "        f.write('Id,Category\\n')\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEWcIlKmkjwj"
      },
      "source": [
        "pred = VQA_net.predict(test_generator)\n",
        "results = {}\n",
        "for i in range(len(pred)):\n",
        "    results[test_generator.answers[i]] = np.argmax(pred[i])\n",
        "\n",
        "create_csv(results, results_dir='./drive/MyDrive/Assignment_3/Results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-4-tUZLvW2W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}